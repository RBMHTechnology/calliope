akka {
  actor {
    serializers {
      calliope-sequenced-event = "com.rbmhtechnology.calliope.serializer.DelegatingSequencedEventSerializer"
    }

    serialization-bindings {
      "com.rbmhtechnology.calliope.SequencedEvent" = calliope-sequenced-event
    }
  }
}

calliope {
  dispatchers {
    pinned-dispatcher {
      type = PinnedDispatcher
      executor = "thread-pool-executor"
    }
  }

  transactional-event-producer {
    # Kafka bootstrap servers
    bootstrap-servers = ""

    # The timeout after which a missing event indicated by a gap in the
    # source sequence-numbers will be skipped.
    # Should be set to the maximum timeout of the underlying transactions.
    transaction-timeout = 30s

    # Determines the number of events fetched per read-request
    # from an Event-Store.
    read-buffer-size = 100

    # Determines the interval in which read-requests are performed
    # if no explicit commit-notification is published by an Event-Store.
    read-interval = 10s

    # The interval in which replicated events are removed from
    # the Event-Store.
    delete-interval = 30s

    producer: ${akka.kafka.producer}
    producer.kafka-clients {
      # Ensures that each message sent to Kafka is confirmed by all
      # in-sync replicas before a successful response is returned
      # to the client.
      acks = -1

      # Retries failed send-requests to Kafka with Integer.MAX_VALUE
      # to avoid loss of messages.
      retries = 2147483647

      # Blocks invocations of producer.send() in case of an exhausted
      # write-buffer until Long.MAX_VALUE is reached to avoid loss of
      # messages.
      max.block.ms = 9223372036854775807

      # Limits concurrent requests for a single partition to a single
      # request to prevent re-ordering of messages on retries.
      max.in.flight.requests.per.connection = 1
    }
  }
}